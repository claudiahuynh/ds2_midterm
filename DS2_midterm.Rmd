---
title: "DS2_midterm"
author: "My An Huynh, Soomin You"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r message = FALSE}
library(tidyverse)
library(MASS)
library(caret)
library(corrplot)
library(mgcv)
library(patchwork)
library(ggplot2)
library(gtsummary)
```

## Load Data
```{r}
load("data/dat1.RData")
load("data/dat2.RData")
```

## Summary Statistics 
```{r}
#train data 
train = dat1 |>
  dplyr::select(-id)

x = model.matrix(log_antibody ~ ., data = train)[, -1]
y = train$log_antibody

#test data 
test = dat2 |> 
  dplyr::select(-id)

x_test = model.matrix(log_antibody ~ ., data = test)[, -1]
y_test = test$log_antibody

tbl_summary(train)
```

Both the train data and the test data were loaded and separated into response variable and predictor variable matrices. A summary statistics table was made to summarize the mean and proportions of the train data. 

\newpage

The following is a brief explanation of the predictor variables and the response variable summarized in the table above. 

* race (1 = White, 2 = Asian, 3 = Black, 4 = Hispanic)
* gender (0 = Female, 1 = Male)
* smoking levels (0 = non-smoker, 1 = former smoker, 2 = current smoker)
* hypertension (0 = no hypertension, 1 = hypertension)
* diabetes (0 = non-diabetic, 1 = diabetic)
* SBP (systolic blood pressure in mmHg)
* LDL (LDL cholesterol in mg/dL)
* age (years)
* height (cm)
* weight (kg)
* BMI (kg/m^2) 
* time (time passed since vaccination in days). 
* log_antibody (log transformed antibody level) 


## Exploratory Data Analysis 
```{r eda}
theme1 = trellis.par.get()
theme1$plot.symbol$col = rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch = 16
theme1$plot.line$col = rgb(.8, .1, .1, 1)
theme1$plot.line$lwd = 2
theme1$strip.background$col = rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

featurePlot(x = train[, -c(2,3,4,8,9,13)], 
            y = train$log_antibody, 
            plot = "scatter", 
            span = 0.5,
            type = c("p", "smooth"), 
            labels = c("Predictors", "Log_antibody"))

# boxplot for factor/binary variables 
p1 = ggplot(aes(x = factor(gender), y = log_antibody), data = train) + 
  geom_boxplot() 
p2 = ggplot(aes(x = factor(race), y = log_antibody), data = train) + 
  geom_boxplot()
p3 = ggplot(aes(x = factor(diabetes), y = log_antibody), data = train) + 
  geom_boxplot()
p4 = ggplot(aes(x = factor(hypertension), y = log_antibody), data = train) + 
  geom_boxplot()
p5 = ggplot(aes(x = factor(smoking), y = log_antibody), data = train) + 
  geom_boxplot()
p1 + p2 + p3 + p4 + p5

corrplot(cor(x), method = "circle", type = "full")
```

Scatterplots were made for the numeric predictor variables and boxplots were made for the factor or binary variables. 

According to the scatterplots for `Systolic blood pressure (SBP)`, `LDL cholesterol (LDL)`, `Time since vaccination (time)`,  `Age (age)`, `Height (height)`, `Weight (weight)`, `BMI (bmi)`, they all indicate relatively linear relationship with the response variable `Log-transformed antibody level (log_antibody)`. Also, the boxplots indicate that the the factor and binary predictors show Gaussian characteristic. 

Correlation plot was also checked and no strong multicolinearity was observed in the data. 


## Model training 
To find an optimal prediction model of antibody levels that show the impact of the demographic and clinical factors, we decided to build various models and compare. We used linear, elastic net, PLS, MARS and GAM models as shown below. 

```{r linear}
#linear
ctrl1 = trainControl(method = "cv", number = 10)

set.seed(1)
linear_mod = train(x, y,
                   method = "lm", 
                   trControl = ctrl1)
summary(linear_mod)

# test error 
lm_pred = predict(linear_mod, newdata = x_test)
lm_rmse = sqrt(mean((y_test - lm_pred)^2))

cat("Test error for the linear model: ", lm_rmse, "\n")
```


```{r elastic net}
# elastic net 
set.seed(1)
enet_mod = train(x = x, 
                 y = y, 
                 method = "glmnet", 
                 tuneGrid = expand.grid(alpha = seq(0, 1, length = 25), 
                                        lambda = exp(seq(-2, 2, length = 100))),
                 trControl = ctrl1)

best_alpha = enet_mod$bestTune$alpha
best_lambda = enet_mod$bestTune$lambda

# test error 
enet_pred = predict(enet_mod, newdata = x_test)
enet_rmse = sqrt(mean((y_test - enet_pred)^2))

cat("The optimal alpha for the elastic net model: ", best_alpha, "\n")
cat("The optimal alpha for the elastic net model: ", best_lambda, "\n")
cat("Test error for the linear model: ", enet_rmse, "\n")
```


```{r pls}
# pls model
set.seed(1)
pls_mod = train(x = x,
                y = y, 
                method = "pls", 
                tuneGrid = data.frame(ncomp = 1:15), 
                trControl = ctrl1, 
                preProcess = c("center", "scale"))
summary(pls_mod)

# test error 
pls_pred = predict(pls_mod, newdata = x_test)
pls_rmse = sqrt(mean((y_test - pls_pred)^2))

cat("Test error for the linear model: ", pls_rmse, "\n")

ggplot(pls_mod, highlight = TRUE)
```

```{r}
# mars
set.seed(1)
mars_mod = train(x = x, 
                 y = y, 
                 method = "earth", 
                 trControl = ctrl1)

summary(mars_mod)

# test error 
mars_pred = predict(mars_mod, newdata = x_test)
mars_rmse = sqrt(mean((y_test - mars_pred)^2))

cat("Test error for the linear model: ", mars_rmse, "\n")

pdp::partial(mars_mod, pred.var = c("bmi"), grid.resolution = 10) |>
  autoplot()
```

To better understand the relationship, partial dependence plot (PDP) for BMI predictor variable and the response variable was plotted. 

```{r}
# gam  
set.seed(1)
gam_mod = train(x = x, 
                y = y, 
                method = "gam", 
                trControl = ctrl1)

gam_mod$bestTune
gam_mod$finalModel

summary(gam_mod)

# test error 
gam_pred = predict(gam_mod, newdata = x_test)
gam_rmse = sqrt(mean((y_test - gam_pred)^2))

cat("Test error for the linear model: ", gam_rmse, "\n")
```


## Model validation 

```{r}
set.seed(1)
resamp = resamples(list(lm = linear_mod, 
                        enet = enet_mod, 
                        pls = pls_mod,                         
                        MARS = mars_mod, 
                        GAM = gam_mod))
summary(resamp)
bwplot(resamp, metric = "RMSE")
```

According to the model comparison via 10-fold cross validation, the mean RMSE of the MARS model is the lowest for this specific dataset and predefined seed. Hence, MARS is chosen as the final model to predict the relationship between log-transformed antibody levels and the predictors of interest. Also, MARS offers better interpretability. 


